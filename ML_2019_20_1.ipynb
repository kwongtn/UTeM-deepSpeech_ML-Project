{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_2019/20-1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwongtn/UTeM-deepSpeech_ML-Project/blob/master/ML_2019_20_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAOShRkRvGeZ",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive for Data Collection and saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ7uaAhKwajM",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aupbne8svGx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f2ddef61-394b-4f5a-8bc0-1ee92940a2a1"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#@markdown Mounting path for Google Drive\n",
        "mountPath = \"/content/drive\" #@param{type: \"string\"}\n",
        "\n",
        "#@markdown Select a folder as path for project file placement\n",
        "projPath = \"/My Drive/@temp/ML-Project_2019-20_1\" #@param {type: \"string\"}\n",
        "projPath = mountPath + projPath\n",
        "\n",
        "drive.mount(mountPath) \n",
        "\n",
        "#@markdown Use \"projPath\" as all variables that need access to the project folder."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working directory will be changed to /content/drive/My Drive/@temp/ML-Project_2019-20_1\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBYvQsncmSiC",
        "colab_type": "text"
      },
      "source": [
        "# Install and use existing DeepSpeech model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueUhFn1-ufLh",
        "colab_type": "code",
        "outputId": "56d76ddd-7070-4aff-a2be-51693437bc33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Create and activate a virtualenv\n",
        "!pip install virtualenv\n",
        "!virtualenv -p python3 \"$projPath\"/deepspeech-gpu-venv/\n",
        "!source \"$projPath\"/deepspeech-gpu-venv/bin/activate"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting virtualenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/77/6a86ef945ad39aae34aed4cc1ae4a2f941b9870917a974ed7c5b6f137188/virtualenv-16.7.8-py2.py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: virtualenv\n",
            "Successfully installed virtualenv-16.7.8\n",
            "Already using interpreter /usr/bin/python3\n",
            "Using base prefix '/usr'\n",
            "New python executable in /root/tmp/deepspeech-gpu-venv/bin/python3\n",
            "Also creating executable in /root/tmp/deepspeech-gpu-venv/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbIB4uSxukqn",
        "colab_type": "code",
        "outputId": "50e76f31-6af0-4822-f575-36dc8b9f1e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Install DeepSpeech CUDA enabled package\n",
        "!pip3 install deepspeech-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/55/38684b6bf0191157fa9bbcc36fe33e7a5701be3b21970efd2f0f30316ea1/deepspeech_gpu-0.5.1-cp36-cp36m-manylinux1_x86_64.whl (44.3MB)\n",
            "\u001b[K     |████████████████████████████████| 44.3MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from deepspeech-gpu) (1.17.4)\n",
            "Installing collected packages: deepspeech-gpu\n",
            "Successfully installed deepspeech-gpu-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AON4BY15u2AK",
        "colab_type": "code",
        "outputId": "9207e794-70eb-49a4-86ac-c683535d61ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Download pre-trained English model and extract\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/deepspeech-0.5.1-models.tar.gz\n",
        "!tar xvfz deepspeech-0.5.1-models.tar.gz\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   620    0   620    0     0   2594      0 --:--:-- --:--:-- --:--:--  2605\n",
            "100 1828M  100 1828M    0     0  57.2M      0  0:00:31  0:00:31 --:--:-- 24.7M\n",
            "./._deepspeech-0.5.1-models\n",
            "deepspeech-0.5.1-models/\n",
            "deepspeech-0.5.1-models/._lm.binary\n",
            "deepspeech-0.5.1-models/lm.binary\n",
            "deepspeech-0.5.1-models/._output_graph.pbmm\n",
            "deepspeech-0.5.1-models/output_graph.pbmm\n",
            "deepspeech-0.5.1-models/._output_graph.pb\n",
            "deepspeech-0.5.1-models/output_graph.pb\n",
            "deepspeech-0.5.1-models/._trie\n",
            "deepspeech-0.5.1-models/trie\n",
            "deepspeech-0.5.1-models/._output_graph.tflite\n",
            "deepspeech-0.5.1-models/output_graph.tflite\n",
            "deepspeech-0.5.1-models/._alphabet.txt\n",
            "deepspeech-0.5.1-models/alphabet.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-ulFo7wu3Hy",
        "colab_type": "code",
        "outputId": "afcbae58-9121-4055-aaf1-da74e981fbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Download example audio files\n",
        "!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.5.1/audio-0.5.1.tar.gz\n",
        "!tar xvfz audio-0.5.1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   608    0   608    0     0   3200      0 --:--:-- --:--:-- --:--:--  3183\n",
            "\r100  192k  100  192k    0     0   407k      0 --:--:-- --:--:-- --:--:--  407k\n",
            "audio/\n",
            "audio/2830-3980-0043.wav\n",
            "audio/Attribution.txt\n",
            "audio/4507-16021-0012.wav\n",
            "audio/8455-210777-0068.wav\n",
            "audio/License.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVF7eD5RulNa",
        "colab_type": "code",
        "outputId": "fad70f36-8ccb-4a0d-9199-465a95dedc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Transcribe an audio file.\n",
        "!deepspeech --model deepspeech-0.5.1-models/output_graph.pbmm --lm deepspeech-0.5.1-models/lm.binary --trie deepspeech-0.5.1-models/trie --audio audio/2830-3980-0043.wav --alphabet deepspeech-0.5.1-models/alphabet.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file deepspeech-0.5.1-models/output_graph.pbmm\n",
            "TensorFlow: v1.13.1-10-g3e0cc53\n",
            "DeepSpeech: v0.5.1-0-g4b29b78\n",
            "2019-11-27 07:36:08.808275: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-11-27 07:36:08.863259: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-11-27 07:36:08.863393: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:148] kernel driver does not appear to be running on this host (27fa9bba09ff): /proc/driver/nvidia/version does not exist\n",
            "2019-11-27 07:36:08.870182: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n",
            "2019-11-27 07:36:08.870292: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n",
            "2019-11-27 07:36:08.870309: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\n",
            "2019-11-27 07:36:08.870483: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n",
            "Loaded model in 0.0649s.\n",
            "Loading language model from files deepspeech-0.5.1-models/lm.binary deepspeech-0.5.1-models/trie\n",
            "Loaded language model in 0.228s.\n",
            "Running inference.\n",
            "experience proof this\n",
            "Inference took 2.070s for 1.975s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh06sAUEyrzy",
        "colab_type": "text"
      },
      "source": [
        "# Another section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBEyJwU0wdZv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}